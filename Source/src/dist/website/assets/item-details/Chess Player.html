<html>
    <head>
        <link href="../asset-styles.css" rel="stylesheet" type="text/css">
    </head>
    <body>
        <h1 class="header">Chess Player</h1>
        <p class="subber">11/22/2022</p>
        <p class="subber">Disclaimer: During the development of this bot, I only played unranked games against myself.</p>
        <h2 class="section">Introduction</h2>
        <p class="content">
            Lately, I noticed an oddly high amount of people I know play chess on chess.com in their free time. I had just finished making a bot that used image recognition from pyautogui to automatically complete quests in AdventureQuest Worlds and figured it would be fun and challenging to make a bot to automatically play chess. From the previous bot, I gained experience comparing individual pixels, but I never got a chance to use the image recognition that is built into pyautogui and thought that using it to detect the positions of chess pieces would be perfect. Going into the project, I thought I would be following a tutorial on how to apply a minimax algorithm for chess.
        </p>
        <p class="content">
            I originally wasn’t going to make the bot for ethical issues, but a friend of mine taunted me about the bot, so I had to make it just to be able to beat him.
        </p>
        <h2 class="section">Development</h2>
        <p class="content">
            Before the creation of the bot, I knew I needed to find an algorithm and I found an article about a complete tutorial for the minimax algorithm for chess. I followed the tutorial to the end and got a working minimax chess ai. At the end of the tutorial, the author decided to pit the ai against other ai such as Stockfish and Stockfish dominated the minimax algorithm. Conveniently, the author linked a download link to the Stockfish executable, which could be called with a python library, so I used that.
        </p>
        <p class="content">
            The first step to determining what move to play would be to get the state of the board. I used chess.com’s built-in ai trainers to test the bot. I knew I wanted to end up using image recognition for the parts, but I wanted to see if there was another way to get the board. I figured that if there was some sort of output the game gave to get the previous move in the form of a string, it would be easy to keep track of the current state of the board. Unfortunately, I wasn’t able to find this, so I looked around and found an option to export the current state of the board as a fen string by copying it to clipboard. I was able to use a library to get the copied string from the clipboard to get the current state of the game. 
        </p>
        <p class="content">
            I implemented the entire bot using this method of getting the board state from the export option and challenged my friend. It turned out that the export option was only available in games against bots, so it was an embarrassing loss for the bot.
        </p>
        <p class="content">
            I went back to using image recognition, which worked extremely unreliably. At first, the bot would almost never report the correct pieces and I couldn’t figure out why. After debugging, I discovered that the background of the pieces was interfering with the image recognition since it was expecting a totally green background and received a tan background.
        </p>
        <p class="content">
            To use image recognition, the bot screenshots all the pieces at the start of each game and saves them in a dictionary. The problem with this is that the starting piece of a pawn could have a tan background but the current position has a green background. It took quite a bit of debugging to figure out this was the reason because for some reason, I totally expected the image recognition to be able to differentiate background from the object.
        </p>
        <p class="content">
            After a little bit of thinking, the solution I came up with was to change the background color of the image to match the board before searching for each piece. It just switched every pixel that isn’t completely white or completely black and did image recognition for each. Although it takes quite some time (~20 seconds) to get the current state of the board, it is extremely reliable.
        </p>
        <p class="content">
            I made the assumption that white would always be on the bottom, which caused the bot to sometimes register the black pieces as white pieces and white pieces as black pieces. This would cause Stockfish to get confused, since the pieces were on the wrong sides of the board. I fixed this issue with the setting that white is always on bottom, but this caused another issue.
        </p>
        <p class="content">
            Since the setting that white was always on bottom was turned on, it became unknown to the bot whether or not it was supposed to play for the top player or the bottom player. I recently used pytesseract for the Jurassic bot player, and I figured that I could use it here too. Just like with the Jurassic player, tesseract spit out gibberish when it was reading text and when I was developing the chess bot, I didn’t have time to try various methods to improve the recognition. I noticed that every time it read my name, although it was gibberish, it spat the same thing out every time, so I picked characters that appeared in my name and not often in other people’s names. The criteria I ended up using for searching for the name “beepbopboopbopbeep106” is if it contains “=” and “[0” when it looks at the name. 
        </p>
        <h2 class="section">Analysis</h2>
        <p class="content">
            The bot is now able to beat its opponent on chess.com every time. After a roller coaster of ups and downs, I succeeded in my original goal of having the bot beat my friend in chess. Since both the bot and chess.com use Stockfish to evaluate moves, the bot makes only perfect moves according to the post game summary.
        </p>
        <p class="content">
            I learned a lot about image recognition and pyautogui, since this project is the first time I used full image recognition, rather than just pixel matching for the bots. I also got practice with algorithms used such as converting between screen coordinates and the chess grid.
        </p>
    </body>
</html>